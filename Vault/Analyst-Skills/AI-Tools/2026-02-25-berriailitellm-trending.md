---
title: BerriAI/litellm (trending)
date: '2026-02-25'
source: https://github.com/BerriAI/litellm
domain: AI-Tools
relevance: ðŸŸ¡
tags:
- '#ai'
- '#python'
related:
- '[[2026-02-22-building-a-fully-local-offline-trading-research-memory-agent-with-zvec]]'
- '[[2026-02-22-build-a-rag-system-with-python-and-a-local-llm-no-api-costs]]'
- '[[2026-02-22-when-llms-interview-each-other]]'
- '[[2026-02-23-5-python-async-patterns-every-ai-engineer-needs]]'
- '[[2026-02-22-give-your-ai-agent-long-term-memory-with-sqlite-and-ollama]]'
- '[[2026-02-23-intro-to-codedecipher-me]]'
status: unread
---

> **TL;DR:** Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, Hugginâ€¦

## Whatâ€™s new and why it matters
Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]

## How to apply
- Extract 1 actionable tactic from this post and try it on a real dataset this week.
- Reproduce the example in a notebook; then refactor into a reusable function.
- Add a short note: what changed in your workflow?

## Relevance
ðŸŸ¡

## Source
https://github.com/BerriAI/litellm

## Related notes
- [[2026-02-22-building-a-fully-local-offline-trading-research-memory-agent-with-zvec]]
- [[2026-02-22-build-a-rag-system-with-python-and-a-local-llm-no-api-costs]]
- [[2026-02-22-when-llms-interview-each-other]]
- [[2026-02-23-5-python-async-patterns-every-ai-engineer-needs]]
- [[2026-02-22-give-your-ai-agent-long-term-memory-with-sqlite-and-ollama]]
- [[2026-02-23-intro-to-codedecipher-me]]
